model:
  type: "mpgnn"
  gnn_layers: 8
  mlp_output_size: 16
  mlp_layers: 4
  mlp_channels: 128
  weight_mlp_layers: 4
  weight_mlp_channels: 16
  weighted_mp: False
  use_edge_weights: True
  use_node_weights: True
  norm: "batch_norm"
loss:
  add_bce: True
  beta_bce_nodes : 3
  beta_bce_edges : 33
  beta_bce_pvs : None
dataset:
  data_type : "homogeneous"
  data_dir: ../datasets/truth_inclusive_10k_49193
training:
  train: True
  starting_learning_rate: 0.001
  batch_size: 8
  dropped_lr_epochs: 2
  epochs: 30
  model_file: "Final_full_graph_8block_32_epochs_weighted_message_passing_BCE.pt"
inference:
  model_file: "../bn_trainings/Final_full_graph_8block_36_epochs_message_passing_BCE_batch_norm.pt"
  name: "test_wmp_BCE_full_graphs"  
  results_dir: "../paper_results/testrun_wmpgnn"
