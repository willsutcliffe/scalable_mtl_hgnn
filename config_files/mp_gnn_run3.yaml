model:
  type: "mpgnn"
  gnn_layers: 2 #8
  mlp_output_size: 8 #16
  mlp_layers: 2 #4
  mlp_channels: 32 #128
  weight_mlp_layers: 2 #4
  weight_mlp_channels: 8 #16
  weighted_mp: True
  use_edge_weights: True
  use_node_weights: True
  norm: "batch_norm"
  LCA_classes: 5
loss:
  bce_constraints: True
  lambda_bce : 0.2
dataset:
  data_type : "homogeneous"
  # data_dir: /user/gr1/lhcb/scapelli/DFEI/lhcbdfei/data_handling/input_formatting/run3/magup
  # data_dir: /eos/user/e/ebornand/DFEI/FullMC/npy_array/magdown
  data_dir: /panfs/ebornand/DFEI/FullMC/npy_array/magdown

training:
  train: True
  starting_learning_rate: 0.001
  epochs: 1 #3
  dropped_lr_epochs: 1 #2
  batch_size: 8 #32
  model_file: "Final_{dataset_data_type}_{model_gnn_layers}block_{training_epochs}_epochs_message_passing_BCE.pt"
inference:
  inference: True
  learning_rate: 0.001
  batch_size: 32