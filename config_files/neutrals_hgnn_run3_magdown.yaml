model:
  type: "neutral_heterognn"
  gnn_layers: 6 #8
  mlp_output_size:  32 #16
  mlp_layers: 4 #4
  mlp_channels: 128 #128
  weight_mlp_layers: 16 #8
  weight_mlp_channels: 32 #16
  weighted_mp: False
  use_edge_weights: True
  use_node_weights: True
  node_types: ['chargedtree', 'neutrals']
  edge_types: ["chargedtree_neutrals"]
  norm: "batch_norm"
  neutrals_classes: 2
  threshold: 0.5
  dropout: 0.5
loss:
  add_bce: False
  beta_edge_bce : 0.2
dataset:
  data_type: "neutrals"
  polarity: "magdown"
  # data_dir: "/eos/user/e/ebornand/DFEI/FullMC/npy_array"
  # data_dir: /panfs/ebornand/DFEI/FullMC/npy_array/magdown/neutrals_/
  data_dir: "/home/ebornand/Data/DFEI/FullMC/npy_array/"
  evt_max_train: 79500
  evt_max_val: 10754 #
  evt_max_test: 0
  load_graph: False
  save_graph: True
  balanced_classes: True
training:
  train: True
  starting_learning_rate: 0.001
  epochs: 50
  dropped_lr_epochs: 5
  batch_size: 256
  early_stopping_patience: 6
  early_stopping_min_delta: 0.001
  load_checkpoint: False
  save_checkpoint: True
  k_subsetRandomSampler: 4
  model_file: "Final_{dataset_data_type}_{dataset_polarity}_{model_gnn_layers}block_{training_epochs}+{training_dropped_lr_epochs}_epochs_message_passing_BCE.pt"
inference:
  inference: True
  learning_rate: 0.0001
  batch_size: 16

#mem-per-gpu